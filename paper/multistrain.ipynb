{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ffbe303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:16:34.273401Z",
     "start_time": "2022-01-03T06:16:31.615869Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/0ml94kbd37bdb3f0y3rx3wfc0000gr/T/ipykernel_59182/891896057.py:7: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\")\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# %matplotlib inline\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom IPython.display import set_matplotlib_formats\\n\\nset_matplotlib_formats(\\\"svg\\\")\\n\\nimport numpy as np\\nimport pandas as pd\\n\\nimport jax.numpy as jnp\\nimport jax\\nfrom jax import vmap\\nfrom jax.scipy.special import xlogy\\n\\njax.config.update(\\\"jax_enable_x64\\\", True)\\nimport scipy.linalg\\n\\nfrom collections import defaultdict\\nimport gzip\\n\\nfrom Bio import AlignIO\\nfrom Bio.Align import MultipleSeqAlignment\\nfrom ete3 import Tree\\nfrom datetime import datetime, MINYEAR\\n\\nfrom vbsky.fasta import SeqData\\nfrom vbsky.bdsky import _lognorm_logpdf\\nfrom vbsky.prob import VF\\nfrom vbsky.prob.distribution import PointMass\\nfrom vbsky.prob.transform import (\\n    Transform,\\n    Compose,\\n    Affine,\\n    Blockwise,\\n    Positive,\\n    ZeroOne,\\n    DiagonalAffine,\\n    Householder,\\n    Shift,\\n    Scale,\\n    Bounded,\\n    Exp,\\n    Softplus,\\n    Concat,\\n)\\nfrom vbsky.prob.distribution import Constant\\nfrom vbsky.prob import arf\\n\\nfrom vbsky.plot import *\\n\\npos = Compose(DiagonalAffine, Exp)\\nplus = Compose(DiagonalAffine, Positive)\\nz1 = Compose(DiagonalAffine, ZeroOne)\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# %matplotlib inline\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom IPython.display import set_matplotlib_formats\\n\\nset_matplotlib_formats(\\\"svg\\\")\\n\\nimport numpy as np\\nimport pandas as pd\\n\\nimport jax.numpy as jnp\\nimport jax\\nfrom jax import vmap\\nfrom jax.scipy.special import xlogy\\n\\njax.config.update(\\\"jax_enable_x64\\\", True)\\nimport scipy.linalg\\n\\nfrom collections import defaultdict\\nimport gzip\\n\\nfrom Bio import AlignIO\\nfrom Bio.Align import MultipleSeqAlignment\\nfrom ete3 import Tree\\nfrom datetime import datetime, MINYEAR\\n\\nfrom vbsky.fasta import SeqData\\nfrom vbsky.bdsky import _lognorm_logpdf\\nfrom vbsky.prob import VF\\nfrom vbsky.prob.distribution import PointMass\\nfrom vbsky.prob.transform import (\\n    Transform,\\n    Compose,\\n    Affine,\\n    Blockwise,\\n    Positive,\\n    ZeroOne,\\n    DiagonalAffine,\\n    Householder,\\n    Shift,\\n    Scale,\\n    Bounded,\\n    Exp,\\n    Softplus,\\n    Concat,\\n)\\nfrom vbsky.prob.distribution import Constant\\nfrom vbsky.prob import arf\\n\\nfrom vbsky.plot import *\\n\\npos = Compose(DiagonalAffine, Exp)\\nplus = Compose(DiagonalAffine, Positive)\\nz1 = Compose(DiagonalAffine, ZeroOne)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"svg\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import vmap\n",
    "from jax.scipy.special import xlogy\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import scipy.linalg\n",
    "\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from ete3 import Tree\n",
    "from datetime import datetime, MINYEAR\n",
    "\n",
    "from vbsky.fasta import SeqData\n",
    "from vbsky.bdsky import _lognorm_logpdf\n",
    "from vbsky.prob import VF\n",
    "from vbsky.prob.distribution import PointMass\n",
    "from vbsky.prob.transform import (\n",
    "    Transform,\n",
    "    Compose,\n",
    "    Affine,\n",
    "    Blockwise,\n",
    "    Positive,\n",
    "    ZeroOne,\n",
    "    DiagonalAffine,\n",
    "    Householder,\n",
    "    Shift,\n",
    "    Scale,\n",
    "    Bounded,\n",
    "    Exp,\n",
    "    Softplus,\n",
    "    Concat,\n",
    ")\n",
    "from vbsky.prob.distribution import Constant\n",
    "from vbsky.prob import arf\n",
    "\n",
    "from vbsky.plot import *\n",
    "\n",
    "pos = Compose(DiagonalAffine, Exp)\n",
    "plus = Compose(DiagonalAffine, Positive)\n",
    "z1 = Compose(DiagonalAffine, ZeroOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efdd1e3",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17e010a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:16:48.082349Z",
     "start_time": "2022-01-03T06:16:47.950165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def _params_prior_loglik(params):\\n    ll = 0\\n    tau = {\\\"R\\\": params[\\\"precision_R\\\"][0], \\\"s\\\": params[\\\"precision_s\\\"][0]}\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"R\\\"], a=0.001, scale=1 / 0.001)\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"s\\\"], a=0.001, scale=1 / 0.001)\\n\\n    ll += jax.scipy.stats.beta.logpdf(params[\\\"s\\\"], 0.02, 0.98).sum()\\n\\n    #     mus = [0.5, 4.1, -2]\\n    #     sigmas = [1, 0.5, 0.5]\\n\\n    mus = [1.0, -1.2]\\n    sigmas = [1, 0.1]\\n\\n    for i, k in enumerate([\\\"R\\\", \\\"origin\\\"]):\\n        #     for i, k in enumerate([\\\"R\\\"]):\\n        log_rate = jnp.log(params[k])\\n        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\\n\\n    for k in [\\\"R\\\", \\\"s\\\"]:\\n        log_rate = jnp.log(params[k])\\n        if k in [\\\"R\\\", \\\"delta\\\", \\\"s\\\"]:\\n            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\\n            m = len(log_rate)\\n            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\\n    return ll\\n\\n\\ndef _params_prior_loglik_less_smooth(params):\\n    ll = 0\\n    tau = {\\\"R\\\": params[\\\"precision_R\\\"][0], \\\"s\\\": params[\\\"precision_s\\\"][0]}\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"R\\\"], a=10, scale=0.1 / 10)\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"s\\\"], a=10, scale=0.1 / 10)\\n\\n    ll += jax.scipy.stats.beta.logpdf(params[\\\"s\\\"], 0.02, 0.98).sum()\\n\\n    #     mus = [0.5, 4.1, -2]\\n    #     sigmas = [1, 0.5, 0.5]\\n\\n    mus = [1.0, -1.2]\\n    sigmas = [1, 0.1]\\n\\n    for i, k in enumerate([\\\"R\\\", \\\"origin\\\"]):\\n        #     for i, k in enumerate([\\\"R\\\"]):\\n        log_rate = jnp.log(params[k])\\n        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\\n\\n    for k in [\\\"R\\\", \\\"s\\\"]:\\n        log_rate = jnp.log(params[k])\\n        if k in [\\\"R\\\", \\\"delta\\\", \\\"s\\\"]:\\n            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\\n            m = len(log_rate)\\n            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\\n    return ll\\n\\n\\ndef _params_prior_loglik_bias(params):\\n    ll = 0\\n    tau = {\\\"R\\\": params[\\\"precision_R\\\"][0], \\\"s\\\": params[\\\"precision_s\\\"][0]}\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"R\\\"], a=0.001, scale=1 / 0.001)\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"s\\\"], a=10, scale=150 / 10)\\n\\n    ll += jax.scipy.stats.beta.logpdf(params[\\\"s\\\"], 0.02, 0.98).sum()\\n\\n    #     mus = [0.5, 4.1, -2]\\n    #     sigmas = [1, 0.5, 0.5]\\n\\n    mus = [1.0, -3.5]\\n    sigmas = [1, 0.05]\\n\\n    #     for i, k in enumerate([\\\"R\\\", \\\"origin\\\"]):\\n    for i, k in enumerate([\\\"R\\\"]):\\n        log_rate = jnp.log(params[k])\\n        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\\n\\n    for k in [\\\"R\\\", \\\"s\\\"]:\\n        log_rate = jnp.log(params[k])\\n        if k in [\\\"R\\\", \\\"delta\\\", \\\"s\\\"]:\\n            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\\n            m = len(log_rate)\\n            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\\n    return ll\\n\\n\\npriors = {\\n    \\\"original\\\": _params_prior_loglik,\\n    \\\"less\\\": _params_prior_loglik_less_smooth,\\n    \\\"bias\\\": _params_prior_loglik_bias,\\n}\\n\\n\\ndef default_flows(data, m, rate):\\n\\n    local_flows = [\\n        {\\\"proportions\\\": Transform(td.n - 2, z1), \\\"root_proportion\\\": Transform(1, z1)}\\n        for td in data.tds\\n    ]\\n\\n    global_flows = VF(\\n        origin=Transform(1, pos),\\n        #         origin=Constant(0.3),\\n        origin_start=Constant(data.earliest),\\n        # delta=Transform(m, pos),\\n        delta=Constant(np.repeat(36.5, m)),\\n        R=Transform(m, pos),\\n        rho_m=Constant(0),\\n        s=Transform(m, z1),\\n        #         s=Constant(np.repeat(0.02, m)),\\n        # precision=Constant(1.0),\\n        precision_R=Transform(1, pos),\\n        precision_s=Transform(1, pos),\\n        clock_rate=Constant(rate),\\n    )\\n    return global_flows, local_flows\\n\\n\\ndef fixed_origin_flows(data, m, rate):\\n\\n    local_flows = [\\n        {\\\"proportions\\\": Transform(td.n - 2, z1), \\\"root_proportion\\\": Transform(1, z1)}\\n        for td in data.tds\\n    ]\\n\\n    global_flows = VF(\\n        origin=Constant(0.3),\\n        origin_start=Constant(data.earliest),\\n        delta=Constant(np.repeat(36.5, m)),\\n        R=Transform(m, pos),\\n        rho_m=Constant(0),\\n        s=Transform(m, z1),\\n        precision_R=Transform(1, pos),\\n        precision_s=Transform(1, pos),\\n        clock_rate=Constant(rate),\\n    )\\n    return global_flows, local_flows\";\n",
       "                var nbb_formatted_code = \"def _params_prior_loglik(params):\\n    ll = 0\\n    tau = {\\\"R\\\": params[\\\"precision_R\\\"][0], \\\"s\\\": params[\\\"precision_s\\\"][0]}\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"R\\\"], a=0.001, scale=1 / 0.001)\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"s\\\"], a=0.001, scale=1 / 0.001)\\n\\n    ll += jax.scipy.stats.beta.logpdf(params[\\\"s\\\"], 0.02, 0.98).sum()\\n\\n    #     mus = [0.5, 4.1, -2]\\n    #     sigmas = [1, 0.5, 0.5]\\n\\n    mus = [1.0, -1.2]\\n    sigmas = [1, 0.1]\\n\\n    for i, k in enumerate([\\\"R\\\", \\\"origin\\\"]):\\n        #     for i, k in enumerate([\\\"R\\\"]):\\n        log_rate = jnp.log(params[k])\\n        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\\n\\n    for k in [\\\"R\\\", \\\"s\\\"]:\\n        log_rate = jnp.log(params[k])\\n        if k in [\\\"R\\\", \\\"delta\\\", \\\"s\\\"]:\\n            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\\n            m = len(log_rate)\\n            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\\n    return ll\\n\\n\\ndef _params_prior_loglik_less_smooth(params):\\n    ll = 0\\n    tau = {\\\"R\\\": params[\\\"precision_R\\\"][0], \\\"s\\\": params[\\\"precision_s\\\"][0]}\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"R\\\"], a=10, scale=0.1 / 10)\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"s\\\"], a=10, scale=0.1 / 10)\\n\\n    ll += jax.scipy.stats.beta.logpdf(params[\\\"s\\\"], 0.02, 0.98).sum()\\n\\n    #     mus = [0.5, 4.1, -2]\\n    #     sigmas = [1, 0.5, 0.5]\\n\\n    mus = [1.0, -1.2]\\n    sigmas = [1, 0.1]\\n\\n    for i, k in enumerate([\\\"R\\\", \\\"origin\\\"]):\\n        #     for i, k in enumerate([\\\"R\\\"]):\\n        log_rate = jnp.log(params[k])\\n        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\\n\\n    for k in [\\\"R\\\", \\\"s\\\"]:\\n        log_rate = jnp.log(params[k])\\n        if k in [\\\"R\\\", \\\"delta\\\", \\\"s\\\"]:\\n            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\\n            m = len(log_rate)\\n            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\\n    return ll\\n\\n\\ndef _params_prior_loglik_bias(params):\\n    ll = 0\\n    tau = {\\\"R\\\": params[\\\"precision_R\\\"][0], \\\"s\\\": params[\\\"precision_s\\\"][0]}\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"R\\\"], a=0.001, scale=1 / 0.001)\\n    ll += jax.scipy.stats.gamma.logpdf(tau[\\\"s\\\"], a=10, scale=150 / 10)\\n\\n    ll += jax.scipy.stats.beta.logpdf(params[\\\"s\\\"], 0.02, 0.98).sum()\\n\\n    #     mus = [0.5, 4.1, -2]\\n    #     sigmas = [1, 0.5, 0.5]\\n\\n    mus = [1.0, -3.5]\\n    sigmas = [1, 0.05]\\n\\n    #     for i, k in enumerate([\\\"R\\\", \\\"origin\\\"]):\\n    for i, k in enumerate([\\\"R\\\"]):\\n        log_rate = jnp.log(params[k])\\n        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\\n\\n    for k in [\\\"R\\\", \\\"s\\\"]:\\n        log_rate = jnp.log(params[k])\\n        if k in [\\\"R\\\", \\\"delta\\\", \\\"s\\\"]:\\n            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\\n            m = len(log_rate)\\n            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\\n    return ll\\n\\n\\npriors = {\\n    \\\"original\\\": _params_prior_loglik,\\n    \\\"less\\\": _params_prior_loglik_less_smooth,\\n    \\\"bias\\\": _params_prior_loglik_bias,\\n}\\n\\n\\ndef default_flows(data, m, rate):\\n\\n    local_flows = [\\n        {\\\"proportions\\\": Transform(td.n - 2, z1), \\\"root_proportion\\\": Transform(1, z1)}\\n        for td in data.tds\\n    ]\\n\\n    global_flows = VF(\\n        origin=Transform(1, pos),\\n        #         origin=Constant(0.3),\\n        origin_start=Constant(data.earliest),\\n        # delta=Transform(m, pos),\\n        delta=Constant(np.repeat(36.5, m)),\\n        R=Transform(m, pos),\\n        rho_m=Constant(0),\\n        s=Transform(m, z1),\\n        #         s=Constant(np.repeat(0.02, m)),\\n        # precision=Constant(1.0),\\n        precision_R=Transform(1, pos),\\n        precision_s=Transform(1, pos),\\n        clock_rate=Constant(rate),\\n    )\\n    return global_flows, local_flows\\n\\n\\ndef fixed_origin_flows(data, m, rate):\\n\\n    local_flows = [\\n        {\\\"proportions\\\": Transform(td.n - 2, z1), \\\"root_proportion\\\": Transform(1, z1)}\\n        for td in data.tds\\n    ]\\n\\n    global_flows = VF(\\n        origin=Constant(0.3),\\n        origin_start=Constant(data.earliest),\\n        delta=Constant(np.repeat(36.5, m)),\\n        R=Transform(m, pos),\\n        rho_m=Constant(0),\\n        s=Transform(m, z1),\\n        precision_R=Transform(1, pos),\\n        precision_s=Transform(1, pos),\\n        clock_rate=Constant(rate),\\n    )\\n    return global_flows, local_flows\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _params_prior_loglik(params):\n",
    "    ll = 0\n",
    "    tau = {\"R\": params[\"precision_R\"][0], \"s\": params[\"precision_s\"][0]}\n",
    "    ll += jax.scipy.stats.gamma.logpdf(tau[\"R\"], a=0.001, scale=1 / 0.001)\n",
    "    ll += jax.scipy.stats.gamma.logpdf(tau[\"s\"], a=0.001, scale=1 / 0.001)\n",
    "\n",
    "    ll += jax.scipy.stats.beta.logpdf(params[\"s\"], 0.02, 0.98).sum()\n",
    "\n",
    "    #     mus = [0.5, 4.1, -2]\n",
    "    #     sigmas = [1, 0.5, 0.5]\n",
    "\n",
    "    mus = [1.0, -1.2]\n",
    "    sigmas = [1, 0.1]\n",
    "\n",
    "    for i, k in enumerate([\"R\", \"origin\"]):\n",
    "        #     for i, k in enumerate([\"R\"]):\n",
    "        log_rate = jnp.log(params[k])\n",
    "        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\n",
    "\n",
    "    for k in [\"R\", \"s\"]:\n",
    "        log_rate = jnp.log(params[k])\n",
    "        if k in [\"R\", \"delta\", \"s\"]:\n",
    "            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\n",
    "            m = len(log_rate)\n",
    "            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\n",
    "    return ll\n",
    "\n",
    "\n",
    "def _params_prior_loglik_less_smooth(params):\n",
    "    ll = 0\n",
    "    tau = {\"R\": params[\"precision_R\"][0], \"s\": params[\"precision_s\"][0]}\n",
    "    ll += jax.scipy.stats.gamma.logpdf(tau[\"R\"], a=10, scale=0.1 / 10)\n",
    "    ll += jax.scipy.stats.gamma.logpdf(tau[\"s\"], a=10, scale=0.1 / 10)\n",
    "\n",
    "    ll += jax.scipy.stats.beta.logpdf(params[\"s\"], 0.02, 0.98).sum()\n",
    "\n",
    "    #     mus = [0.5, 4.1, -2]\n",
    "    #     sigmas = [1, 0.5, 0.5]\n",
    "\n",
    "    mus = [1.0, -1.2]\n",
    "    sigmas = [1, 0.1]\n",
    "\n",
    "    for i, k in enumerate([\"R\", \"origin\"]):\n",
    "        #     for i, k in enumerate([\"R\"]):\n",
    "        log_rate = jnp.log(params[k])\n",
    "        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\n",
    "\n",
    "    for k in [\"R\", \"s\"]:\n",
    "        log_rate = jnp.log(params[k])\n",
    "        if k in [\"R\", \"delta\", \"s\"]:\n",
    "            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\n",
    "            m = len(log_rate)\n",
    "            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\n",
    "    return ll\n",
    "\n",
    "\n",
    "def _params_prior_loglik_bias(params):\n",
    "    ll = 0\n",
    "    tau = {\"R\": params[\"precision_R\"][0], \"s\": params[\"precision_s\"][0]}\n",
    "    ll += jax.scipy.stats.gamma.logpdf(tau[\"R\"], a=0.001, scale=1 / 0.001)\n",
    "    ll += jax.scipy.stats.gamma.logpdf(tau[\"s\"], a=10, scale=150 / 10)\n",
    "\n",
    "    ll += jax.scipy.stats.beta.logpdf(params[\"s\"], 0.02, 0.98).sum()\n",
    "\n",
    "    #     mus = [0.5, 4.1, -2]\n",
    "    #     sigmas = [1, 0.5, 0.5]\n",
    "\n",
    "    mus = [1.0, -3.5]\n",
    "    sigmas = [1, 0.1]\n",
    "\n",
    "    #     for i, k in enumerate([\"R\", \"origin\"]):\n",
    "    for i, k in enumerate([\"R\"]):\n",
    "        log_rate = jnp.log(params[k])\n",
    "        ll += _lognorm_logpdf(log_rate, mu=mus[i], sigma=sigmas[i]).sum()\n",
    "\n",
    "    for k in [\"R\", \"s\"]:\n",
    "        log_rate = jnp.log(params[k])\n",
    "        if k in [\"R\", \"delta\", \"s\"]:\n",
    "            ll -= (tau[k] / 2) * (jnp.diff(log_rate) ** 2).sum()\n",
    "            m = len(log_rate)\n",
    "            ll += xlogy((m - 1) / 2, tau[k] / (2 * jnp.pi))\n",
    "    return ll\n",
    "\n",
    "\n",
    "priors = {\n",
    "    \"original\": _params_prior_loglik,\n",
    "    \"less\": _params_prior_loglik_less_smooth,\n",
    "    \"bias\": _params_prior_loglik_bias,\n",
    "}\n",
    "\n",
    "\n",
    "def default_flows(data, m, rate):\n",
    "\n",
    "    local_flows = [\n",
    "        {\"proportions\": Transform(td.n - 2, z1), \"root_proportion\": Transform(1, z1)}\n",
    "        for td in data.tds\n",
    "    ]\n",
    "\n",
    "    global_flows = VF(\n",
    "        origin=Transform(1, pos),\n",
    "        #         origin=Constant(0.3),\n",
    "        origin_start=Constant(data.earliest),\n",
    "        # delta=Transform(m, pos),\n",
    "        delta=Constant(np.repeat(36.5, m)),\n",
    "        R=Transform(m, pos),\n",
    "        rho_m=Constant(0),\n",
    "        s=Transform(m, z1),\n",
    "        #         s=Constant(np.repeat(0.02, m)),\n",
    "        # precision=Constant(1.0),\n",
    "        precision_R=Transform(1, pos),\n",
    "        precision_s=Transform(1, pos),\n",
    "        clock_rate=Constant(rate),\n",
    "    )\n",
    "    return global_flows, local_flows\n",
    "\n",
    "\n",
    "def fixed_origin_flows(data, m, rate):\n",
    "\n",
    "    local_flows = [\n",
    "        {\"proportions\": Transform(td.n - 2, z1), \"root_proportion\": Transform(1, z1)}\n",
    "        for td in data.tds\n",
    "    ]\n",
    "\n",
    "    global_flows = VF(\n",
    "        origin=Constant(0.3),\n",
    "        origin_start=Constant(data.earliest),\n",
    "        delta=Constant(np.repeat(36.5, m)),\n",
    "        R=Transform(m, pos),\n",
    "        rho_m=Constant(0),\n",
    "        s=Transform(m, z1),\n",
    "        precision_R=Transform(1, pos),\n",
    "        precision_s=Transform(1, pos),\n",
    "        clock_rate=Constant(rate),\n",
    "    )\n",
    "    return global_flows, local_flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-vision",
   "metadata": {},
   "source": [
    "## Import Covid sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "built-forty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.571408Z",
     "start_time": "2022-01-03T06:16:49.361661Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cl/0ml94kbd37bdb3f0y3rx3wfc0000gr/T/ipykernel_59182/3352858568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfasta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfasta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"florida\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlignIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"covid/audacity_fl.fa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfasta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"michigan\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlignIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"covid/audacity_mi.fa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfasta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usa\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlignIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"covid/audacity_usa.fa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/Bio/AlignIO/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(handle, format, seq_count)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0malignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No records found in handle\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/Bio/AlignIO/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(handle, format, seq_count)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown format '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/Bio/AlignIO/__init__.py\u001b[0m in \u001b[0;36m_SeqIO_to_alignment_iterator\u001b[0;34m(handle, format, seq_count)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Must assume that there is a single alignment using all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# the SeqRecord objects:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mMultipleSeqAlignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/Bio/SeqIO/Interfaces.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_close_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/Bio/SeqIO/FastaIO.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mSeqRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSimpleFastaParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0mfirst_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/Bio/SeqIO/FastaIO.py\u001b[0m in \u001b[0;36mSimpleFastaParser\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\">\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"fasta = {}\\nfasta[\\\"florida\\\"] = AlignIO.read(\\\"covid/audacity_fl.fa\\\", format=\\\"fasta\\\")\\nfasta[\\\"michigan\\\"] = AlignIO.read(\\\"covid/audacity_mi.fa\\\", format=\\\"fasta\\\")\\nfasta[\\\"usa\\\"] = AlignIO.read(\\\"covid/audacity_usa.fa\\\", format=\\\"fasta\\\")\";\n",
       "                var nbb_formatted_code = \"fasta = {}\\nfasta[\\\"florida\\\"] = AlignIO.read(\\\"covid/audacity_fl.fa\\\", format=\\\"fasta\\\")\\nfasta[\\\"michigan\\\"] = AlignIO.read(\\\"covid/audacity_mi.fa\\\", format=\\\"fasta\\\")\\nfasta[\\\"usa\\\"] = AlignIO.read(\\\"covid/audacity_usa.fa\\\", format=\\\"fasta\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fasta = {}\n",
    "fasta[\"florida\"] = AlignIO.read(\"covid/audacity_fl.fa\", format=\"fasta\")\n",
    "fasta[\"michigan\"] = AlignIO.read(\"covid/audacity_mi.fa\", format=\"fasta\")\n",
    "fasta[\"usa\"] = AlignIO.read(\"covid/audacity_usa.fa\", format=\"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9683f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.574643Z",
     "start_time": "2022-01-03T06:17:14.574628Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {k: SeqData(v) for k, v in fasta.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d463f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.576482Z",
     "start_time": "2022-01-03T06:17:14.576458Z"
    }
   },
   "outputs": [],
   "source": [
    "df_variant = pd.read_csv(\"covid/variant_surveillance.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062722b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.577816Z",
     "start_time": "2022-01-03T06:17:14.577800Z"
    }
   },
   "outputs": [],
   "source": [
    "strains = {}\n",
    "for k, v in data.items():\n",
    "    df_k = df_variant.loc[df_variant[\"Accession ID\"].isin(v.seqs)]\n",
    "    v_dict = {}\n",
    "    v_dict[\"delta\"] = SeqData(\n",
    "        MultipleSeqAlignment(\n",
    "            df_k.loc[df_k[\"Variant\"].str.contains(\"Delta\", na=False), \"Accession ID\"]\n",
    "            .map(v.seqs)\n",
    "            .tolist()\n",
    "        ),\n",
    "        left_end=datetime(2021, 2, 23),\n",
    "    )\n",
    "    v_dict[\"alpha\"] = SeqData(\n",
    "        MultipleSeqAlignment(\n",
    "            df_k.loc[df_k[\"Variant\"].str.contains(\"Alpha\", na=False), \"Accession ID\"]\n",
    "            .map(v.seqs)\n",
    "            .tolist()\n",
    "        ),\n",
    "        left_end=datetime(2020, 11, 15),\n",
    "    )\n",
    "    strains[k] = v_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f71f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.579472Z",
     "start_time": "2022-01-03T06:17:14.579436Z"
    }
   },
   "outputs": [],
   "source": [
    "# def filter_audacity_tree(subset, name):\n",
    "#     global_tree = Tree(\"covid/global.tree\", format=1)\n",
    "#     leaves = set([leaf.name for leaf in global_tree])\n",
    "\n",
    "#     to_prune = []\n",
    "\n",
    "#     for s in subset:\n",
    "#         desc = s.description.split(\"|\")\n",
    "#         to_prune.append(desc[1])\n",
    "\n",
    "#     global_tree.prune(to_prune, preserve_branch_length=True)\n",
    "#     global_tree.write(outfile=f\"covid/global_{name}.tree\")\n",
    "\n",
    "\n",
    "# for k1 in strains.keys():\n",
    "#     for k2, v in strains[k1].items():\n",
    "#         filter_audacity_tree(v.aln, f\"{k1}_{k2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-shakespeare",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-jumping",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.580962Z",
     "start_time": "2022-01-03T06:17:14.580944Z"
    }
   },
   "outputs": [],
   "source": [
    "n_tips = 200\n",
    "temp_folder = \"covid/temp\"\n",
    "tree_path = \"covid/temp/subsample.trees\"\n",
    "audacity = True\n",
    "stratified = False\n",
    "stratify_by = None\n",
    "\n",
    "for k1 in strains.keys():\n",
    "    for k2, v in strains[k1].items():\n",
    "        print(k1, k2)\n",
    "        audacity_tree_path = f\"covid/global_{k1}_{k2}.tree\"\n",
    "\n",
    "        if stratified:\n",
    "            stratify_by = defaultdict(list)\n",
    "            for s, d in zip(v.sids, v.dates):\n",
    "                days = (v.max_date - d).days\n",
    "                stratify_by[(d.year, (d.month - 1) // 3)].append(s)\n",
    "\n",
    "        n_trees = min(int(np.ceil(v.n / n_tips)), 50)\n",
    "\n",
    "        v.prep_data(\n",
    "            n_tips,\n",
    "            n_trees,\n",
    "            temp_folder,\n",
    "            tree_path,\n",
    "            audacity=audacity,\n",
    "            audacity_tree_path=audacity_tree_path,\n",
    "            stratified=stratified,\n",
    "            stratify_by=stratify_by,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899edbda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.583188Z",
     "start_time": "2022-01-03T06:17:14.583170Z"
    }
   },
   "outputs": [],
   "source": [
    "rate = 1.10e-3\n",
    "m = 50\n",
    "\n",
    "for k in strains.keys():\n",
    "    for v in strains[k].values():\n",
    "        global_flows, local_flows = default_flows(v, m, rate)\n",
    "        v.setup_flows(global_flows, local_flows)\n",
    "\n",
    "rng = jax.random.PRNGKey(6)\n",
    "res = {}\n",
    "n_iter = 10\n",
    "step_size = 1.0\n",
    "threshold = 0.001\n",
    "for k in strains.keys():\n",
    "    res1 = {}\n",
    "    for k1, v in strains[k].items():\n",
    "        print(k, k1)\n",
    "        res1[k1] = v.loop(\n",
    "            _params_prior_loglik, rng, n_iter, step_size=step_size, threshold=threshold\n",
    "        )\n",
    "    res[k] = res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6894ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.584985Z",
     "start_time": "2022-01-03T06:17:14.584967Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.set_size_inches(10, 15)\n",
    "\n",
    "for i, b in enumerate([\"florida\", \"michigan\", \"usa\"]):\n",
    "    for strain in [\"alpha\", \"delta\"]:\n",
    "        start, top, end, x0 = plot_helper(res[b][strain], strains[b][strain], 200)\n",
    "        if b == \"usa\":\n",
    "            title = b.upper()\n",
    "        else:\n",
    "            title = b.title()\n",
    "        plot_one(\n",
    "            res[b][strain],\n",
    "            axs[i],\n",
    "            \"R\",\n",
    "            m,\n",
    "            start,\n",
    "            top,\n",
    "            end,\n",
    "            x0,\n",
    "            strain.title(),\n",
    "            \"fill\",\n",
    "            title,\n",
    "        )\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim(2020.8, 2021.9)\n",
    "    ax.set_ylim(0, 2)\n",
    "axs[0].legend(loc=\"lower left\")\n",
    "\n",
    "fig.savefig(\"covid/figures/strains/strain_R.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577d4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T06:17:14.586640Z",
     "start_time": "2022-01-03T06:17:14.586627Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.set_size_inches(10, 15)\n",
    "\n",
    "for i, b in enumerate([\"florida\", \"michigan\", \"usa\"]):\n",
    "    for strain in [\"alpha\", \"delta\"]:\n",
    "        start, top, end, x0 = plot_helper(res[b][strain], strains[b][strain], 200)\n",
    "        if b == \"usa\":\n",
    "            title = b.upper()\n",
    "        else:\n",
    "            title = b.title()\n",
    "        plot_one(\n",
    "            res[b][strain],\n",
    "            axs[i],\n",
    "            \"s\",\n",
    "            m,\n",
    "            start,\n",
    "            top,\n",
    "            end,\n",
    "            x0,\n",
    "            strain.title(),\n",
    "            \"fill\",\n",
    "            title,\n",
    "        )\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim(2020.8, 2021.9)\n",
    "axs[0].legend(loc=\"lower left\")\n",
    "\n",
    "fig.savefig(\"covid/figures/strains/strain_s.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6576ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T19:08:19.953999Z",
     "start_time": "2021-11-15T19:08:16.898133Z"
    }
   },
   "source": [
    "## BEAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddf0043c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T20:36:01.903581Z",
     "start_time": "2021-11-15T20:36:01.734256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"def sample_beast_tips(\\n    k1, k2, n=200, stratified=False, stratify_by=None, stratified_handle=\\\"\\\"\\n):\\n    d = strains[k1][k2]\\n    dates_dict = {d1: d2 for d1, d2 in zip(d.sids, d.dates)}\\n    if stratified:\\n        if stratify_by is None:\\n            stratify_by = d.sample_months\\n        key_list = [k for k, v in stratify_by.items() if len(v) > 50]\\n\\n        seqs = []\\n        ell = len(key_list)\\n        mod = n % ell\\n        floor = n // ell\\n        for i in range(ell):\\n            sequence_pool = stratify_by[key_list[i]]\\n            if i < mod:\\n                size = floor + 1\\n            else:\\n                size = floor\\n            seqs.append(np.random.choice(sequence_pool, size=size, replace=False))\\n        seqs = np.concatenate(seqs)\\n        aln_sample = MultipleSeqAlignment([d.seqs[s] for s in seqs])\\n    else:\\n        inds = np.random.choice(len(d.aln._records), size=n, replace=False)\\n        aln_sample = MultipleSeqAlignment([d.aln[int(inds[0])]])\\n        for j in range(1, n):\\n            aln_sample.append(d.aln[int(inds[j])])\\n\\n    for r in aln_sample:\\n        sp = r.description.split(\\\"|\\\")\\n        r.id = sp[0] + \\\"_\\\" + dates_dict[r.name].strftime(\\\"%Y-%m-%d\\\")\\n    #         r.description = \\\"\\\"\\n\\n    handle = f\\\"covid/beast/multistrain/{k1}_{k2}_beast\\\"\\n    if stratified:\\n        handle += stratified_handle\\n    handle += \\\".fa\\\"\\n    with open(handle, \\\"w\\\") as output_handle:\\n        count = AlignIO.write(aln_sample, output_handle, \\\"fasta\\\")\";\n",
       "                var nbb_formatted_code = \"def sample_beast_tips(\\n    k1, k2, n=200, stratified=False, stratify_by=None, stratified_handle=\\\"\\\"\\n):\\n    d = strains[k1][k2]\\n    dates_dict = {d1: d2 for d1, d2 in zip(d.sids, d.dates)}\\n    if stratified:\\n        if stratify_by is None:\\n            stratify_by = d.sample_months\\n        key_list = [k for k, v in stratify_by.items() if len(v) > 50]\\n\\n        seqs = []\\n        ell = len(key_list)\\n        mod = n % ell\\n        floor = n // ell\\n        for i in range(ell):\\n            sequence_pool = stratify_by[key_list[i]]\\n            if i < mod:\\n                size = floor + 1\\n            else:\\n                size = floor\\n            seqs.append(np.random.choice(sequence_pool, size=size, replace=False))\\n        seqs = np.concatenate(seqs)\\n        aln_sample = MultipleSeqAlignment([d.seqs[s] for s in seqs])\\n    else:\\n        inds = np.random.choice(len(d.aln._records), size=n, replace=False)\\n        aln_sample = MultipleSeqAlignment([d.aln[int(inds[0])]])\\n        for j in range(1, n):\\n            aln_sample.append(d.aln[int(inds[j])])\\n\\n    for r in aln_sample:\\n        sp = r.description.split(\\\"|\\\")\\n        r.id = sp[0] + \\\"_\\\" + dates_dict[r.name].strftime(\\\"%Y-%m-%d\\\")\\n    #         r.description = \\\"\\\"\\n\\n    handle = f\\\"covid/beast/multistrain/{k1}_{k2}_beast\\\"\\n    if stratified:\\n        handle += stratified_handle\\n    handle += \\\".fa\\\"\\n    with open(handle, \\\"w\\\") as output_handle:\\n        count = AlignIO.write(aln_sample, output_handle, \\\"fasta\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample_beast_tips(\n",
    "    k1, k2, n=200, stratified=False, stratify_by=None, stratified_handle=\"\"\n",
    "):\n",
    "    d = strains[k1][k2]\n",
    "    dates_dict = {d1: d2 for d1, d2 in zip(d.sids, d.dates)}\n",
    "    if stratified:\n",
    "        if stratify_by is None:\n",
    "            stratify_by = d.sample_months\n",
    "        key_list = [k for k, v in stratify_by.items() if len(v) > 50]\n",
    "\n",
    "        seqs = []\n",
    "        ell = len(key_list)\n",
    "        mod = n % ell\n",
    "        floor = n // ell\n",
    "        for i in range(ell):\n",
    "            sequence_pool = stratify_by[key_list[i]]\n",
    "            if i < mod:\n",
    "                size = floor + 1\n",
    "            else:\n",
    "                size = floor\n",
    "            seqs.append(np.random.choice(sequence_pool, size=size, replace=False))\n",
    "        seqs = np.concatenate(seqs)\n",
    "        aln_sample = MultipleSeqAlignment([d.seqs[s] for s in seqs])\n",
    "    else:\n",
    "        inds = np.random.choice(len(d.aln._records), size=n, replace=False)\n",
    "        aln_sample = MultipleSeqAlignment([d.aln[int(inds[0])]])\n",
    "        for j in range(1, n):\n",
    "            aln_sample.append(d.aln[int(inds[j])])\n",
    "\n",
    "    for r in aln_sample:\n",
    "        sp = r.description.split(\"|\")\n",
    "        r.id = sp[0] + \"_\" + dates_dict[r.name].strftime(\"%Y-%m-%d\")\n",
    "    #         r.description = \"\"\n",
    "\n",
    "    handle = f\"covid/beast/multistrain/{k1}_{k2}_beast\"\n",
    "    if stratified:\n",
    "        handle += stratified_handle\n",
    "    handle += \".fa\"\n",
    "    with open(handle, \"w\") as output_handle:\n",
    "        count = AlignIO.write(aln_sample, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "206161a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T20:36:05.165207Z",
     "start_time": "2021-11-15T20:36:03.510180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"stratified = False\\n# stratified_handle = \\\"_quarters\\\"\\nstratified_handle = \\\"\\\"\\nn = 200\\n\\nfor k1, v in strains.items():\\n    #     stratify_by = defaultdict(list)\\n    #     for s, d in zip(v.sids, v.dates):\\n    #         days = (v.max_date - d).days\\n    #         stratify_by[(d.year, (d.month - 1) // 3)].append(s)\\n    for k2 in v.keys():\\n        # sample_beast_tips(k, n, stratified, stratify_by, stratified_handle)\\n        sample_beast_tips(k1, k2, n, stratified)\";\n",
       "                var nbb_formatted_code = \"stratified = False\\n# stratified_handle = \\\"_quarters\\\"\\nstratified_handle = \\\"\\\"\\nn = 200\\n\\nfor k1, v in strains.items():\\n    #     stratify_by = defaultdict(list)\\n    #     for s, d in zip(v.sids, v.dates):\\n    #         days = (v.max_date - d).days\\n    #         stratify_by[(d.year, (d.month - 1) // 3)].append(s)\\n    for k2 in v.keys():\\n        # sample_beast_tips(k, n, stratified, stratify_by, stratified_handle)\\n        sample_beast_tips(k1, k2, n, stratified)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stratified = False\n",
    "# stratified_handle = \"_quarters\"\n",
    "stratified_handle = \"\"\n",
    "n = 200\n",
    "\n",
    "for k1, v in strains.items():\n",
    "    #     stratify_by = defaultdict(list)\n",
    "    #     for s, d in zip(v.sids, v.dates):\n",
    "    #         days = (v.max_date - d).days\n",
    "    #         stratify_by[(d.year, (d.month - 1) // 3)].append(s)\n",
    "    for k2 in v.keys():\n",
    "        # sample_beast_tips(k, n, stratified, stratify_by, stratified_handle)\n",
    "        sample_beast_tips(k1, k2, n, stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2a560b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T22:33:06.500472Z",
     "start_time": "2021-11-15T22:33:06.462144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"import xml.etree.ElementTree as ET\";\n",
       "                var nbb_formatted_code = \"import xml.etree.ElementTree as ET\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1490e214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T23:31:18.008660Z",
     "start_time": "2021-11-15T23:31:17.970027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"def edit_template(k1, k2):\\n    aln = AlignIO.read(f\\\"covid/beast/multistrain/{k1}_{k2}_beast.fa\\\", \\\"fasta\\\")\\n\\n    tree = ET.parse(f\\\"covid/beast/multistrain/template.xml\\\")\\n    root = tree.getroot()\\n\\n    value = \\\"\\\"\\n    for rec, child in zip(aln, root.find(\\\"data\\\")):\\n        seq = str(rec.seq)\\n        child.set(\\\"id\\\", f\\\"seq_{rec.name}\\\")\\n        child.set(\\\"taxon\\\", rec.name)\\n        child.set(\\\"value\\\", seq)\\n        value += f\\\"{rec.name}={rec.name.split('_')[1]},\\\"\\n    root.find(\\\"run\\\").find(\\\"state\\\").find(\\\"tree\\\").find(\\\"trait\\\").set(\\\"value\\\", value[:-1])\\n\\n    for log in root.find(\\\"run\\\").findall(\\\"logger\\\"):\\n        if log.get(\\\"id\\\") == \\\"tracelog\\\":\\n            log.set(\\\"fileName\\\", f\\\"covid/beast/multistrain/logs/{k1}_{k2}_beast.log\\\")\\n        if log.get(\\\"id\\\") == \\\"treelog.t:template\\\":\\n            log.set(\\\"fileName\\\", f\\\"covid/beast/multistrain/trees/{k1}_{k2}_beast.log\\\")\\n\\n    xml_str = ET.tostring(root, encoding=\\\"unicode\\\")\\n    #     xml_str.replace('sim6\\\"', f'sim{i}\\\"')\\n    with open(f\\\"covid/beast/multistrain/{k1}_{k2}_beast.xml\\\", \\\"w\\\") as xml:\\n        xml.write(xml_str)\";\n",
       "                var nbb_formatted_code = \"def edit_template(k1, k2):\\n    aln = AlignIO.read(f\\\"covid/beast/multistrain/{k1}_{k2}_beast.fa\\\", \\\"fasta\\\")\\n\\n    tree = ET.parse(f\\\"covid/beast/multistrain/template.xml\\\")\\n    root = tree.getroot()\\n\\n    value = \\\"\\\"\\n    for rec, child in zip(aln, root.find(\\\"data\\\")):\\n        seq = str(rec.seq)\\n        child.set(\\\"id\\\", f\\\"seq_{rec.name}\\\")\\n        child.set(\\\"taxon\\\", rec.name)\\n        child.set(\\\"value\\\", seq)\\n        value += f\\\"{rec.name}={rec.name.split('_')[1]},\\\"\\n    root.find(\\\"run\\\").find(\\\"state\\\").find(\\\"tree\\\").find(\\\"trait\\\").set(\\\"value\\\", value[:-1])\\n\\n    for log in root.find(\\\"run\\\").findall(\\\"logger\\\"):\\n        if log.get(\\\"id\\\") == \\\"tracelog\\\":\\n            log.set(\\\"fileName\\\", f\\\"covid/beast/multistrain/logs/{k1}_{k2}_beast.log\\\")\\n        if log.get(\\\"id\\\") == \\\"treelog.t:template\\\":\\n            log.set(\\\"fileName\\\", f\\\"covid/beast/multistrain/trees/{k1}_{k2}_beast.log\\\")\\n\\n    xml_str = ET.tostring(root, encoding=\\\"unicode\\\")\\n    #     xml_str.replace('sim6\\\"', f'sim{i}\\\"')\\n    with open(f\\\"covid/beast/multistrain/{k1}_{k2}_beast.xml\\\", \\\"w\\\") as xml:\\n        xml.write(xml_str)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def edit_template(k1, k2):\n",
    "    aln = AlignIO.read(f\"covid/beast/multistrain/{k1}_{k2}_beast.fa\", \"fasta\")\n",
    "\n",
    "    tree = ET.parse(f\"covid/beast/multistrain/template.xml\")\n",
    "    root = tree.getroot()\n",
    "\n",
    "    value = \"\"\n",
    "    for rec, child in zip(aln, root.find(\"data\")):\n",
    "        seq = str(rec.seq)\n",
    "        child.set(\"id\", f\"seq_{rec.name}\")\n",
    "        child.set(\"taxon\", rec.name)\n",
    "        child.set(\"value\", seq)\n",
    "        value += f\"{rec.name}={rec.name.split('_')[1]},\"\n",
    "    root.find(\"run\").find(\"state\").find(\"tree\").find(\"trait\").set(\"value\", value[:-1])\n",
    "\n",
    "    for log in root.find(\"run\").findall(\"logger\"):\n",
    "        if log.get(\"id\") == \"tracelog\":\n",
    "            log.set(\"fileName\", f\"covid/beast/multistrain/logs/{k1}_{k2}_beast.log\")\n",
    "        if log.get(\"id\") == \"treelog.t:template\":\n",
    "            log.set(\"fileName\", f\"covid/beast/multistrain/trees/{k1}_{k2}_beast.log\")\n",
    "\n",
    "    xml_str = ET.tostring(root, encoding=\"unicode\")\n",
    "    #     xml_str.replace('sim6\"', f'sim{i}\"')\n",
    "    with open(f\"covid/beast/multistrain/{k1}_{k2}_beast.xml\", \"w\") as xml:\n",
    "        xml.write(xml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c53a234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T23:31:19.532888Z",
     "start_time": "2021-11-15T23:31:18.748010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"for k1 in strains.keys():\\n    for k2 in strains[k1].keys():\\n        edit_template(k1, k2)\";\n",
       "                var nbb_formatted_code = \"for k1 in strains.keys():\\n    for k2 in strains[k1].keys():\\n        edit_template(k1, k2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k1 in strains.keys():\n",
    "    for k2 in strains[k1].keys():\n",
    "        edit_template(k1, k2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
